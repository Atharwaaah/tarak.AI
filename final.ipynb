{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 769,
     "referenced_widgets": [
      "6723099e8021472a85aab92396becb89",
      "9ba513dcf6a94fc4b17cb3be6c201300",
      "834f384d47a84ea8bd9ec981313bdcd8",
      "58493f16d4f04ba7b74a33d9b0f8c09b",
      "4fbaf11ef1fe478caa6968f28f664b72",
      "fc03cad50dfe450ca93b48cee7c7f0df",
      "ce45f9848a544387a59f0fc60eaac0ef",
      "e2dc3d412a0241ae837ecc219dec38b3",
      "f1724522a4954f8f9695f28f94dcc219",
      "c83a99335950416a8c94158dce1727ae",
      "96c8e4e022c848e3b860917b42abae8e"
     ]
    },
    "id": "TD50dkdZGbxX",
    "outputId": "74e742e8-839b-45f6-f8a0-2a48dd12220e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6723099e8021472a85aab92396becb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-b3b09572975b>:166: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Pollution Analysis Chat\", height=400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching examples at: '/content/.gradio/cached_examples/39'\n",
      "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "* Running on public URL: https://fe6f9a6454890ad3b1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://fe6f9a6454890ad3b1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q transformers accelerate bitsandbytes gradio torch pillow\n",
    "\n",
    "import torch\n",
    "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "class RiverPollutionAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Initialize model with 4-bit quantization\n",
    "        self.processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n",
    "        self.model = InstructBlipForConditionalGeneration.from_pretrained(\n",
    "            \"Salesforce/instructblip-vicuna-7b\",\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16,\n",
    "            load_in_4bit=True\n",
    "        )\n",
    "\n",
    "        self.pollutants = [\n",
    "            \"plastic waste\", \"chemical foam\", \"industrial discharge\",\n",
    "            \"sewage water\", \"oil spill\", \"organic debris\",\n",
    "            \"construction waste\", \"medical waste\", \"floating trash\",\n",
    "            \"algal bloom\", \"toxic sludge\", \"agricultural runoff\"\n",
    "        ]\n",
    "\n",
    "        self.severity_descriptions = {\n",
    "            1: \"Minimal pollution - Slightly noticeable\",\n",
    "            2: \"Minor pollution - Small amounts visible\",\n",
    "            3: \"Moderate pollution - Clearly visible\",\n",
    "            4: \"Significant pollution - Affecting water quality\",\n",
    "            5: \"Heavy pollution - Obvious environmental impact\",\n",
    "            6: \"Severe pollution - Large accumulation\",\n",
    "            7: \"Very severe pollution - Major ecosystem impact\",\n",
    "            8: \"Extreme pollution - Dangerous levels\",\n",
    "            9: \"Critical pollution - Immediate action needed\",\n",
    "            10: \"Disaster level - Ecological catastrophe\"\n",
    "        }\n",
    "\n",
    "    def analyze_image(self, image):\n",
    "        \"\"\"Analyze river pollution with robust parsing\"\"\"\n",
    "        if not isinstance(image, Image.Image):\n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "        prompt = \"\"\"Analyze this river pollution scene and provide:\n",
    "1. List ALL visible pollutants ONLY from: [plastic waste, chemical foam, industrial discharge, sewage water, oil spill, organic debris, construction waste, medical waste, floating trash, algal bloom, toxic sludge, agricultural runoff]\n",
    "2. Estimate pollution severity from 1-10\n",
    "\n",
    "Respond EXACTLY in this format:\n",
    "Pollutants: [comma separated list]\n",
    "Severity: [number]\"\"\"\n",
    "\n",
    "        inputs = self.processor(\n",
    "            images=image,\n",
    "            text=prompt,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(\"cuda\", torch.float16)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=200,\n",
    "                temperature=0.5,\n",
    "                top_p=0.85,\n",
    "                do_sample=True\n",
    "            )\n",
    "\n",
    "        analysis = self.processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        pollutants, severity = self._parse_response(analysis)\n",
    "        return self._format_analysis(pollutants, severity)\n",
    "\n",
    "    def _parse_response(self, analysis: str) -> Tuple[List[str], int]:\n",
    "        \"\"\"Robust parsing of model response\"\"\"\n",
    "        pollutants = []\n",
    "        severity = 3\n",
    "\n",
    "        # Extract pollutants\n",
    "        pollutant_match = re.search(\n",
    "            r'(?i)(pollutants?|contaminants?)[:\\s]*\\[?(.*?)(?:\\]|Severity|severity|$)',\n",
    "            analysis\n",
    "        )\n",
    "\n",
    "        if pollutant_match:\n",
    "            pollutants_str = pollutant_match.group(2).strip()\n",
    "            pollutants = [\n",
    "                p.strip().lower()\n",
    "                for p in re.split(r'[,;]|\\band\\b', pollutants_str)\n",
    "                if p.strip().lower() in self.pollutants\n",
    "            ]\n",
    "\n",
    "        # Extract severity\n",
    "        severity_match = re.search(\n",
    "            r'(?i)(severity|level)[:\\s]*(\\d{1,2})',\n",
    "            analysis\n",
    "        )\n",
    "\n",
    "        if severity_match:\n",
    "            try:\n",
    "                severity = min(max(int(severity_match.group(2)), 1), 10)\n",
    "            except:\n",
    "                severity = self._calculate_severity(pollutants)\n",
    "        else:\n",
    "            severity = self._calculate_severity(pollutants)\n",
    "\n",
    "        return pollutants, severity\n",
    "\n",
    "    def _calculate_severity(self, pollutants: List[str]) -> int:\n",
    "        \"\"\"Weighted severity calculation\"\"\"\n",
    "        if not pollutants:\n",
    "            return 1\n",
    "\n",
    "        weights = {\n",
    "            \"medical waste\": 3, \"toxic sludge\": 3, \"oil spill\": 2.5,\n",
    "            \"chemical foam\": 2, \"industrial discharge\": 2, \"sewage water\": 2,\n",
    "            \"plastic waste\": 1.5, \"construction waste\": 1.5, \"algal bloom\": 1.5,\n",
    "            \"agricultural runoff\": 1.5, \"floating trash\": 1, \"organic debris\": 1\n",
    "        }\n",
    "\n",
    "        avg_weight = sum(weights.get(p, 1) for p in pollutants) / len(pollutants)\n",
    "        return min(10, max(1, round(avg_weight * 3)))\n",
    "\n",
    "    def _format_analysis(self, pollutants: List[str], severity: int) -> str:\n",
    "        \"\"\"Generate formatted report\"\"\"\n",
    "        severity_bar = f\"\"\"üìä Severity: {severity}/10\n",
    "{\"‚ñà\" * severity}{\"‚ñë\" * (10 - severity)}\n",
    "{self.severity_descriptions.get(severity, '')}\"\"\"\n",
    "\n",
    "        pollutants_list = \"\\nüîç No pollutants detected\" if not pollutants else \"\\n\".join(\n",
    "            f\"{i}. {p.capitalize()}\" for i, p in enumerate(pollutants[:5], 1))\n",
    "\n",
    "        return f\"\"\"üåä River Pollution Analysis üåä\n",
    "{pollutants_list}\n",
    "{severity_bar}\"\"\"\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = RiverPollutionAnalyzer()\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    " # Import your actual analyzer\n",
    "\n",
    "css = \"\"\"\n",
    "/* (Keep all your CSS styles) */\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:\n",
    "    with gr.Column(elem_classes=\"header\"):\n",
    "        gr.Markdown(\"# üåç River Pollution Analyzer\")\n",
    "        gr.Markdown(\"### AI-powered water pollution detection\")\n",
    "\n",
    "    with gr.Row(elem_classes=\"side-by-side\"):\n",
    "        # Left Panel\n",
    "        with gr.Column(elem_classes=\"left-panel\"):\n",
    "            with gr.Group():\n",
    "                image_input = gr.Image(type=\"pil\", label=\"Upload River Image\", height=300)\n",
    "                analyze_btn = gr.Button(\"üîç Analyze Pollution\", variant=\"primary\")\n",
    "\n",
    "            with gr.Group(elem_classes=\"analysis-box\"):\n",
    "                gr.Markdown(\"### üìä Analysis report\")\n",
    "                analysis_output = gr.Markdown()\n",
    "\n",
    "        # Right Panel\n",
    "        with gr.Column(elem_classes=\"right-panel\"):\n",
    "            with gr.Group(elem_classes=\"chat-container\"):\n",
    "                chatbot = gr.Chatbot(label=\"Pollution Analysis Q&A\", height=400)\n",
    "                with gr.Row():\n",
    "                    chat_input = gr.Textbox(placeholder=\"Ask about pollution sources...\",\n",
    "                                         label=\"Your Question\", container=False, scale=5)\n",
    "                    chat_btn = gr.Button(\"üí¨ Ask\", variant=\"secondary\", scale=1)\n",
    "                clear_btn = gr.Button(\"üßπ Clear Chat History\", size=\"sm\")\n",
    "\n",
    "    # Connect to your actual analyzer functions\n",
    "    analyze_btn.click(\n",
    "        analyzer.analyze_image,\n",
    "        inputs=image_input,\n",
    "        outputs=analysis_output\n",
    "    )\n",
    "\n",
    "    chat_input.submit(\n",
    "        lambda msg, chat: (\"\", chat + [(msg, analyzer.analyze_chat(msg))]),\n",
    "        inputs=[chat_input, chatbot],\n",
    "        outputs=[chat_input, chatbot]\n",
    "    )\n",
    "\n",
    "    chat_btn.click(\n",
    "        lambda msg, chat: (\"\", chat + [(msg, analyzer.analyze_chat(msg))]),\n",
    "        inputs=[chat_input, chatbot],\n",
    "        outputs=[chat_input, chatbot]\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        lambda: None,\n",
    "        outputs=[chatbot]\n",
    "    )\n",
    "\n",
    "    # Examples using your real analyzer\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"https://huggingface.co/spaces/atharwaah1work/tarak.AI/resolve/main/polluted_river1.jpg\"],\n",
    "            [\"https://drive.google.com/uc?export=view&id=1WGcXwFhpbD1LrtbQ8E5IZZN3nEGfcwuN\"]\n",
    "        ],\n",
    "        inputs=image_input,\n",
    "        outputs=analysis_output,\n",
    "        fn=analyzer.analyze_image,\n",
    "        cache_examples=True,\n",
    "        label=\"Try example images:\"\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4fbaf11ef1fe478caa6968f28f664b72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58493f16d4f04ba7b74a33d9b0f8c09b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c83a99335950416a8c94158dce1727ae",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_96c8e4e022c848e3b860917b42abae8e",
      "value": "‚Äá4/4‚Äá[02:27&lt;00:00,‚Äá31.41s/it]"
     }
    },
    "6723099e8021472a85aab92396becb89": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ba513dcf6a94fc4b17cb3be6c201300",
       "IPY_MODEL_834f384d47a84ea8bd9ec981313bdcd8",
       "IPY_MODEL_58493f16d4f04ba7b74a33d9b0f8c09b"
      ],
      "layout": "IPY_MODEL_4fbaf11ef1fe478caa6968f28f664b72"
     }
    },
    "834f384d47a84ea8bd9ec981313bdcd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2dc3d412a0241ae837ecc219dec38b3",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f1724522a4954f8f9695f28f94dcc219",
      "value": 4
     }
    },
    "96c8e4e022c848e3b860917b42abae8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ba513dcf6a94fc4b17cb3be6c201300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc03cad50dfe450ca93b48cee7c7f0df",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ce45f9848a544387a59f0fc60eaac0ef",
      "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
     }
    },
    "c83a99335950416a8c94158dce1727ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce45f9848a544387a59f0fc60eaac0ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e2dc3d412a0241ae837ecc219dec38b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1724522a4954f8f9695f28f94dcc219": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fc03cad50dfe450ca93b48cee7c7f0df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
