{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "accelerator": "GPU", "widgets": {"application/vnd.jupyter.widget-state+json": {"dc69a3bd30ce437caa72de1ee32d513d": {"model_module": "@jupyter-widgets/controls", "model_name": "HBoxModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_42c7e27132a1404e9bb0c0313b2dce3d", "IPY_MODEL_ee72f71022d14bf38f16de35d7bc7c02", "IPY_MODEL_eede31b3571648c29609f1233f471202"], "layout": "IPY_MODEL_3ad9db3dbec345e79beabcddb8faeb10"}}, "42c7e27132a1404e9bb0c0313b2dce3d": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_49e20fde0af24d06974c9cb83cb6a13a", "placeholder": "\u200b", "style": "IPY_MODEL_03a1d510a783488f93d8821811e66a98", "value": "Loading\u2007checkpoint\u2007shards:\u2007100%"}}, "ee72f71022d14bf38f16de35d7bc7c02": {"model_module": "@jupyter-widgets/controls", "model_name": "FloatProgressModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_df7aef96b469462a959e9819acee4967", "max": 4, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_7e482f17ab744654855decf99845689e", "value": 4}}, "eede31b3571648c29609f1233f471202": {"model_module": "@jupyter-widgets/controls", "model_name": "HTMLModel", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_d0ceb6e4dfa34bc49a7d3af0775e200e", "placeholder": "\u200b", "style": "IPY_MODEL_07cf0931677d4436a59e25c176e7273f", "value": "\u20074/4\u2007[02:29&lt;00:00,\u200731.86s/it]"}}, "3ad9db3dbec345e79beabcddb8faeb10": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "49e20fde0af24d06974c9cb83cb6a13a": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "03a1d510a783488f93d8821811e66a98": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "df7aef96b469462a959e9819acee4967": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "7e482f17ab744654855decf99845689e": {"model_module": "@jupyter-widgets/controls", "model_name": "ProgressStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "d0ceb6e4dfa34bc49a7d3af0775e200e": {"model_module": "@jupyter-widgets/base", "model_name": "LayoutModel", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "07cf0931677d4436a59e25c176e7273f": {"model_module": "@jupyter-widgets/controls", "model_name": "DescriptionStyleModel", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}}}}, "cells": [{"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 859, "referenced_widgets": ["dc69a3bd30ce437caa72de1ee32d513d", "42c7e27132a1404e9bb0c0313b2dce3d", "ee72f71022d14bf38f16de35d7bc7c02", "eede31b3571648c29609f1233f471202", "3ad9db3dbec345e79beabcddb8faeb10", "49e20fde0af24d06974c9cb83cb6a13a", "03a1d510a783488f93d8821811e66a98", "df7aef96b469462a959e9819acee4967", "7e482f17ab744654855decf99845689e", "d0ceb6e4dfa34bc49a7d3af0775e200e", "07cf0931677d4436a59e25c176e7273f"]}, "id": "CdH3_qTlMAG8", "outputId": "18e4a2b8-7549-433f-9a80-b16f8241d701"}, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n", "WARNING:accelerate.utils.modeling:The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"]}, {"output_type": "display_data", "data": {"text/plain": ["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "dc69a3bd30ce437caa72de1ee32d513d"}}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["<ipython-input-4-e0d41fdffcb1>:286: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n", "  chatbot = gr.Chatbot(\n", "<ipython-input-4-e0d41fdffcb1>:286: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n", "  chatbot = gr.Chatbot(\n"]}, {"output_type": "stream", "name": "stdout", "text": ["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n", "* Running on public URL: https://21d6c276e51dcc6132.gradio.live\n", "\n", "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["<div><iframe src=\"https://21d6c276e51dcc6132.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.11/dist-packages/bitsandbytes/nn/modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n", "  warnings.warn(\n", "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n", "  warnings.warn(\n", "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n", "  warnings.warn(\n"]}], "source": ["!pip install -q transformers accelerate bitsandbytes gradio torch pillow\n", "\n", "import torch\n", "from transformers import InstructBlipProcessor, InstructBlipForConditionalGeneration\n", "import gradio as gr\n", "from PIL import Image\n", "import re\n", "from typing import List, Tuple\n", "\n", "class RiverPollutionAnalyzerInstructBLIP:\n", "    def __init__(self):\n", "        # Initialize model with 4-bit quantization for memory efficiency\n", "        self.processor = InstructBlipProcessor.from_pretrained(\"Salesforce/instructblip-vicuna-7b\")\n", "        self.model = InstructBlipForConditionalGeneration.from_pretrained(\n", "            \"Salesforce/instructblip-vicuna-7b\",\n", "            device_map=\"auto\",\n", "            torch_dtype=torch.float16,\n", "            load_in_4bit=True\n", "        )\n", "\n", "        self.pollutants = [\n", "            \"plastic waste\", \"chemical foam\", \"industrial discharge\",\n", "            \"sewage water\", \"oil spill\", \"organic debris\",\n", "            \"construction waste\", \"medical waste\", \"floating trash\",\n", "            \"algal bloom\", \"toxic sludge\", \"agricultural runoff\"\n", "        ]\n", "\n", "        self.severity_descriptions = {\n", "            1: \"Minimal pollution - Slightly noticeable\",\n", "            2: \"Minor pollution - Small amounts visible\",\n", "            3: \"Moderate pollution - Clearly visible\",\n", "            4: \"Significant pollution - Affecting water quality\",\n", "            5: \"Heavy pollution - Obvious environmental impact\",\n", "            6: \"Severe pollution - Large accumulation\",\n", "            7: \"Very severe pollution - Major ecosystem impact\",\n", "            8: \"Extreme pollution - Dangerous levels\",\n", "            9: \"Critical pollution - Immediate action needed\",\n", "            10: \"Disaster level - Ecological catastrophe\"\n", "        }\n", "\n", "        self.current_image = None\n", "        self.current_pollutants = []\n", "        self.severity = None\n", "        self.chat_history = []\n", "\n", "    def analyze_image(self, image):\n", "        \"\"\"Analyze river pollution using InstructBLIP\"\"\"\n", "        if not isinstance(image, Image.Image):\n", "            image = Image.fromarray(image)\n", "\n", "        self.current_image = image\n", "        self.chat_history = []\n", "\n", "        # More specific prompt for better pollutant detection and severity assessment\n", "        prompt = \"\"\"Carefully analyze this river pollution scene and provide:\n", "1. List ALL visible pollutants from this list: [plastic waste, chemical foam, industrial discharge, sewage water, oil spill, organic debris, construction waste, medical waste, floating trash, algal bloom, toxic sludge, agricultural runoff]\n", "2. Estimate pollution severity from 1-10 based on: pollutant types, coverage area, and water discoloration\n", "\n", "Format your response EXACTLY like this:\n", "Pollutants: [comma separated list]\n", "Severity: [number between 1-10]\"\"\"\n", "\n", "        inputs = self.processor(\n", "            images=image,\n", "            text=prompt,\n", "            return_tensors=\"pt\"\n", "        ).to(\"cuda\", torch.float16)\n", "\n", "        with torch.no_grad():\n", "            outputs = self.model.generate(\n", "                **inputs,\n", "                max_new_tokens=200,\n", "                temperature=0.5,  # Lower temperature for more factual responses\n", "                top_p=0.85,\n", "                do_sample=True\n", "            )\n", "\n", "        analysis = self.processor.batch_decode(outputs, skip_special_tokens=True)[0]\n", "\n", "        # Improved parsing with better error handling\n", "        pollutants = []\n", "        severity = 3  # Default moderate level\n", "\n", "        # Extract pollutants\n", "        if \"Pollutants:\" in analysis:\n", "            pollutants_str = analysis.split(\"Pollutants:\")[1].split(\"Severity:\")[0].strip()\n", "            # Match only from our predefined list\n", "            pollutants = [p.strip().lower() for p in pollutants_str.split(\",\")\n", "                         if p.strip().lower() in self.pollutants]\n", "            self.current_pollutants = [(p, \"N/A\") for p in pollutants[:5]]  # Store top 5 pollutants\n", "\n", "        # Extract severity with better validation\n", "        if \"Severity:\" in analysis:\n", "            try:\n", "                severity_match = re.search(r'Severity:\\s*(\\d+)', analysis)\n", "                if severity_match:\n", "                    severity = int(severity_match.group(1))\n", "                    # Ensure severity is within 1-10 range\n", "                    severity = max(1, min(10, severity))\n", "            except:\n", "                severity = self._calculate_severity(pollutants)\n", "        else:\n", "            severity = self._calculate_severity(pollutants)\n", "\n", "        self.severity = severity\n", "\n", "        return self._format_analysis(pollutants)\n", "\n", "    def _calculate_severity(self, pollutants: List[str]) -> int:\n", "        \"\"\"Calculate severity based on pollutant types and quantities\"\"\"\n", "        if not pollutants:\n", "            return 1  # No pollutants = minimal severity\n", "\n", "        # Weight different pollutants differently\n", "        pollutant_weights = {\n", "            \"medical waste\": 3,\n", "            \"toxic sludge\": 3,\n", "            \"oil spill\": 2.5,\n", "            \"chemical foam\": 2,\n", "            \"industrial discharge\": 2,\n", "            \"sewage water\": 2,\n", "            \"plastic waste\": 1.5,\n", "            \"construction waste\": 1.5,\n", "            \"floating trash\": 1,\n", "            \"organic debris\": 1,\n", "            \"algal bloom\": 1.5,\n", "            \"agricultural runoff\": 1.5\n", "        }\n", "\n", "        total_weight = sum(pollutant_weights.get(p, 1) for p in pollutants)\n", "        avg_weight = total_weight / len(pollutants)\n", "\n", "        # Map to severity scale\n", "        if avg_weight < 1.2:\n", "            return 2\n", "        elif avg_weight < 1.6:\n", "            return 4\n", "        elif avg_weight < 2.0:\n", "            return 6\n", "        elif avg_weight < 2.5:\n", "            return 8\n", "        else:\n", "            return 10\n", "\n", "    def _format_analysis(self, pollutants: List[str]) -> str:\n", "        \"\"\"Generate analysis report focusing on pollutants and severity\"\"\"\n", "        # Generate severity bar\n", "        severity_bar = \"\"\n", "        if self.severity:\n", "            filled = \"\u2588\" * self.severity\n", "            empty = \"\u2591\" * (10 - self.severity)\n", "            severity_bar = f\"\"\"\n", "\ud83d\udcca **Severity Level**: {self.severity}/10\n", "{filled}{empty}\n", "{self.severity_descriptions.get(self.severity, '')}\n", "\"\"\"\n", "\n", "        # Format pollutants list\n", "        pollutants_list = \"\"\n", "        if pollutants:\n", "            pollutants_list = \"\ud83d\udd0d **Detected Pollutants**:\\n\"\n", "            for idx, pollutant in enumerate(pollutants[:5], 1):\n", "                pollutants_list += f\"{idx}. {pollutant.capitalize()}\\n\"\n", "        else:\n", "            pollutants_list = \"\ud83d\udd0d No significant pollutants detected\\n\"\n", "\n", "        # Build the final report\n", "        analysis = f\"\"\"\n", "\ud83c\udf0a **River Pollution Analysis** \ud83c\udf0a\n", "\n", "{severity_bar}\n", "{pollutants_list}\n", "\"\"\"\n", "        return analysis\n", "\n", "    def chat_response(self, message):\n", "        \"\"\"Handle chat questions with context (unchanged)\"\"\"\n", "        if not self.current_image:\n", "            return \"Please analyze an image first!\", self.chat_history\n", "\n", "        # Build context\n", "        context = f\"\"\"Current analysis:\n", "- Pollutants: {', '.join([p[0] for p in self.current_pollutants[:3]])}\n", "- Severity: {self.severity}/10 ({self.severity_descriptions.get(self.severity, '')})\n", "\"\"\"\n", "\n", "        if self.chat_history:\n", "            context += \"\\nPrevious conversation:\\n\" + \"\\n\".join(\n", "                f\"User: {q}\\nAssistant: {a}\" for q, a in self.chat_history[-2:]\n", "            )\n", "\n", "        prompt = f\"\"\"{context}\n", "New question: {message}\n", "Answer specifically about the pollution, considering:\n", "1. Visual evidence in the image\n", "2. Environmental impact\n", "3. Possible solutions\n", "Assistant:\"\"\"\n", "\n", "        inputs = self.processor(\n", "            images=self.current_image,\n", "            text=prompt,\n", "            return_tensors=\"pt\"\n", "        ).to(\"cuda\", torch.float16)\n", "\n", "        with torch.no_grad():\n", "            outputs = self.model.generate(\n", "                **inputs,\n", "                max_new_tokens=250,\n", "                temperature=0.7,\n", "                repetition_penalty=1.2\n", "            )\n", "\n", "        response = self.processor.batch_decode(outputs, skip_special_tokens=True)[0]\n", "\n", "        # Clean response\n", "        if \"Assistant:\" in response:\n", "            response = response.split(\"Assistant:\")[-1].strip()\n", "\n", "        self.chat_history.append((message, response))\n", "        return \"\", self.chat_history\n", "\n", "# Initialize analyzer\n", "try:\n", "    analyzer = RiverPollutionAnalyzerInstructBLIP()\n", "except Exception as e:\n", "    print(f\"Error initializing analyzer: {e}\")\n", "    raise\n", "\n", "# Gradio Interface (unchanged)\n", "css = \"\"\"\n", ".gradio-container {\n", "    max-width: 900px !important;\n", "}\n", ".analysis-box {\n", "    border: 1px solid #e0e0e0;\n", "    border-radius: 8px;\n", "    padding: 15px;\n", "    background: #f9f9f9;\n", "}\n", ".chatbot {\n", "    min-height: 500px;\n", "}\n", ".dark .analysis-box {\n", "    background: #2a2a2a;\n", "    border-color: #444;\n", "}\n", "footer {\n", "    display: none !important;\n", "}\n", ".severity-bar {\n", "    font-family: monospace;\n", "    font-size: 16px;\n", "    line-height: 1.5;\n", "}\n", "\"\"\"\n", "\n", "with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:\n", "    gr.Markdown(\"\"\"\n", "    # \ud83c\udf0d River Pollution Analyzer (InstructBLIP)\n", "    *Upload an image of a river to analyze pollution levels using InstructBLIP model*\n", "    \"\"\")\n", "\n", "    with gr.Row():\n", "        with gr.Column(scale=1, min_width=300):\n", "            with gr.Group():\n", "                image_input = gr.Image(\n", "                    type=\"pil\",\n", "                    label=\"Upload River Image\",\n", "                    elem_classes=\"image-upload\"\n", "                )\n", "                analyze_btn = gr.Button(\n", "                    \"Analyze Pollution\",\n", "                    variant=\"primary\",\n", "                    size=\"lg\"\n", "                )\n", "\n", "            with gr.Group(elem_classes=\"analysis-box\"):\n", "                gr.Markdown(\"### \ud83d\udd2c Analysis Results\")\n", "                analysis_output = gr.Markdown(\n", "                    label=\"\",\n", "                    elem_classes=\"analysis-results\"\n", "                )\n", "\n", "        with gr.Column(scale=2, min_width=500):\n", "            chatbot = gr.Chatbot(\n", "                label=\"Pollution Analysis Chat\",\n", "                bubble_full_width=False,\n", "                height=500,\n", "                elem_classes=\"chatbot\"\n", "            )\n", "\n", "            with gr.Row():\n", "                chat_input = gr.Textbox(\n", "                    placeholder=\"Ask about pollution sources, environmental impact, or cleanup recommendations...\",\n", "                    label=\"Your Question\",\n", "                    container=False,\n", "                    scale=5\n", "                )\n", "                chat_btn = gr.Button(\n", "                    \"Ask\",\n", "                    variant=\"secondary\",\n", "                    scale=1,\n", "                    min_width=100\n", "                )\n", "\n", "            with gr.Row():\n", "                clear_btn = gr.Button(\"Clear Chat History\", size=\"sm\")\n", "                gr.Markdown(\"*Tip: Ask specific questions for detailed answers*\", elem_classes=\"tip-text\")\n", "\n", "    # Analysis action\n", "    analyze_btn.click(\n", "        analyzer.analyze_image,\n", "        inputs=image_input,\n", "        outputs=analysis_output\n", "    )\n", "\n", "    # Chat actions\n", "    chat_msg = chat_input.submit(\n", "        analyzer.chat_response,\n", "        inputs=chat_input,\n", "        outputs=[chat_input, chatbot]\n", "    )\n", "    chat_btn.click(\n", "        analyzer.chat_response,\n", "        inputs=chat_input,\n", "        outputs=[chat_input, chatbot]\n", "    )\n", "\n", "    # Clear chat\n", "    clear_btn.click(\n", "        lambda: ([], []),\n", "        outputs=[chat_input, chatbot]\n", "    )\n", "\n", "    # # # Examples\n", "    # # gr.Examples(\n", "    # #     examples=[\n", "    # #         [\"https://drive.google.com/uc?export=download&id=1mLLW0ilH2o4MEwQ6Ohm8Hv6q9IAxe1AS\"],  # Polluted river\n", "    # #         [\"https://drive.google.com/uc?export=download&id=17O8Ro5ZIJ6G-IXPUVH5s-5Jpd8uUCcmK\"]   # Clean river\n", "    # #     ],\n", "    # #     inputs=image_input,\n", "    # #     outputs=analysis_output,\n", "    # #     fn=analyzer.analyze_image,\n", "    # #     cache_examples=True,\n", "    # #     label=\"Try example images:\"\n", "    # )\n", "\n", "# Launch the demo\n", "demo.launch(debug=True, share=True)"]}]}